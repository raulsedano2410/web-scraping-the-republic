{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_Date(italian_date):\n",
    "    # Mapeo de nombres de meses en italiano a números de mes\n",
    "    meses_italiano_a_numero = {\n",
    "        'gennaio': '01',\n",
    "        'febbraio': '02',\n",
    "        'marzo': '03',\n",
    "        'aprile': '04',\n",
    "        'maggio': '05',\n",
    "        'giugno': '06',\n",
    "        'luglio': '07',\n",
    "        'agosto': '08',\n",
    "        'settembre': '09',\n",
    "        'ottobre': '10',\n",
    "        'novembre': '11',\n",
    "        'dicembre': '12'\n",
    "    }\n",
    "\n",
    "    # Dividir la fecha italiana en partes\n",
    "    partes_fecha = italian_date.split()\n",
    "\n",
    "    # Obtener día, mes y año\n",
    "    dia = partes_fecha[0]\n",
    "    mes = meses_italiano_a_numero[partes_fecha[1]]\n",
    "    año = partes_fecha[2]\n",
    "\n",
    "    # Formatear la fecha en el formato deseado\n",
    "    fecha_formateada = f\"{año}-{mes}-{dia}\"\n",
    "\n",
    "    return fecha_formateada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def create_csv(keyword, from_date, to_date, the_urls):\n",
    "\n",
    "  keyword = keyword.replace(\" \", \"_\")\n",
    "\n",
    "  csv_file_path = '_'.join([keyword, from_date, to_date]) + '.csv'\n",
    "\n",
    "# Transform each URL into a dictionary\n",
    "  data = [{\"URL\": url} for url in the_urls]\n",
    "\n",
    "  if os.path.exists(csv_file_path):\n",
    "    # Si existe, abre el archivo en modo de escritura\n",
    "    with open(csv_file_path, mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
    "\n",
    "        # Escribe los nuevos datos en el archivo\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Data added to existing file: {csv_file_path}\")\n",
    "  else:\n",
    "# If it does not exist, create a new file and write the data\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
    "\n",
    "        # Write the headers\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write the data\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Nuevo archivo CSV creado: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "\n",
    "\n",
    "def get_the_total_number_of_pages(url):\n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text,'html.parser')\n",
    "  root = html.fromstring(str(soup))\n",
    "  try:\n",
    "    paragraph_text = root.xpath('//*[@id=\"lista-risultati\"]/div/p/text()[2]')[0]\n",
    "    total_pages = paragraph_text.split()[1]\n",
    "  except:\n",
    "    total_pages = 0\n",
    "\n",
    "  return int(total_pages)\n",
    "\n",
    "def get_date_of_next_period(url):\n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text,'html.parser')\n",
    "  root = html.fromstring(str(soup))\n",
    "\n",
    "  dates = root.xpath('//*[@id=\"lista-risultati\"]/article/aside/a')[-1]\n",
    "  date = dates.split()[2]\n",
    "  return dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def urls_generator(keyword, from_date, to_date, modality, number_of_pages):\n",
    "\n",
    "    keyword = keyword.replace(\" \", \"+\")\n",
    "\n",
    "    url_base = \"https://ricerca.repubblica.it/ricerca/repubblica?query={}&fromdate={}&todate={}&sortby=adate&author=&mode={}&page={}\"\n",
    "\n",
    "    urls = []\n",
    "\n",
    "    # Generate URLs\n",
    "    for page in range(1, number_of_pages + 1):\n",
    "        url = url_base.format(keyword, from_date, to_date, modality, page)\n",
    "        print(url)\n",
    "        urls.append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ricerca.repubblica.it/ricerca/repubblica?query=tasa&fromdate=1984-01-01&todate=2019-01-01&sortby=adate&author=&mode=all&page=1\n",
      "https://ricerca.repubblica.it/ricerca/repubblica?query=tasa&fromdate=1984-01-01&todate=2019-01-01&sortby=adate&author=&mode=all&page=1\n",
      "https://ricerca.repubblica.it/ricerca/repubblica?query=tasa&fromdate=1984-01-01&todate=2019-01-01&sortby=adate&author=&mode=all&page=2\n",
      "https://ricerca.repubblica.it/ricerca/repubblica?query=tasa&fromdate=1984-01-01&todate=2019-01-01&sortby=adate&author=&mode=all&page=3\n",
      "Data added to existing file: tasa_1984-01-01_2019-01-01.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def scraper(keyword, from_date, to_date, modality):\n",
    "\n",
    "    # returns an array\n",
    "    urls = urls_generator(keyword, from_date, to_date, modality,1)\n",
    "\n",
    "    # returns an number\n",
    "    total_number_of_pages = get_the_total_number_of_pages(urls[0]) # Example 140\n",
    "\n",
    "    # first possibility\n",
    "    if total_number_of_pages == 0:\n",
    "        return print('there is no news with the entry entered')\n",
    "\n",
    "    # second possibility\n",
    "    elif  total_number_of_pages <= 50:\n",
    "        the_urls = urls_generator(keyword, from_date, to_date, modality,total_number_of_pages)\n",
    "\n",
    "        create_csv(keyword, from_date, to_date, the_urls)\n",
    "\n",
    "    # third possibility\n",
    "    else:\n",
    "        max_pages_per_keyword = 50\n",
    "        the_urls = urls_generator(keyword, from_date, to_date, modality, max_pages_per_keyword)\n",
    "\n",
    "        create_csv(keyword, from_date, to_date, the_urls)\n",
    "\n",
    "\n",
    "scraper(\"tasa\", \"1984-01-01\", \"2019-01-01\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 aprile 1984\n",
      "30 agosto 1984\n",
      "13 dicembre 1984\n",
      "25 giugno 1985\n",
      "28 dicembre 1985\n"
     ]
    }
   ],
   "source": [
    "get_date_of_next_period('https://ricerca.repubblica.it/ricerca/repubblica?query=asa&fromdate=1984-01-01&todate=1986-01-01&sortby=adate&author=&mode=all&page=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
